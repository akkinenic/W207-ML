{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1: Digit Classification with KNN and Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, you'll implement your own image recognition system for classifying digits. Read through the code and the instructions carefully and add your own code where indicated. Each problem can be addressed succinctly with the included packages -- please don't add any more. Grading will be based on writing clean, commented code, along with a few short answers.\n",
    "\n",
    "As always, you're welcome to work on the project in groups and discuss ideas on the course wall, but <b> please prepare your own write-up (with your own code). </b>\n",
    "\n",
    "If you're interested, check out these links related to digit recognition:\n",
    "\n",
    "Yann Lecun's MNIST benchmarks: http://yann.lecun.com/exdb/mnist/\n",
    "\n",
    "Stanford Streetview research and data: http://ufldl.stanford.edu/housenumbers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# Import a bunch of libraries.\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Set the randomizer seed so results are the same each time.\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data. Notice that we are splitting the data into training, development, and test. We also have a small subset of the training data called mini_train_data and mini_train_labels that you should use in all the experiments below, unless otherwise noted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expecting object: line 3 column 121540 (char 121541)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-53fe0b905c14>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Load the digit data from https://www.openml.org/d/554 or from default local location `~/scikit_learn_data/...`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfetch_openml\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mnist_784'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_X_y\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Rescale grayscale values to [0,1].\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m255.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kakkineni\\AppData\\Local\\Continuum\\anaconda3\\envs\\ipykernel_py2\\lib\\site-packages\\sklearn\\datasets\\openml.pyc\u001b[0m in \u001b[0;36mfetch_openml\u001b[1;34m(name, version, data_id, data_home, target_column, cache, return_X_y)\u001b[0m\n\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m     \u001b[1;31m# download data features, meta-info about column types\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 556\u001b[1;33m     \u001b[0mfeatures_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_data_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_home\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    557\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    558\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeatures_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kakkineni\\AppData\\Local\\Continuum\\anaconda3\\envs\\ipykernel_py2\\lib\\site-packages\\sklearn\\datasets\\openml.pyc\u001b[0m in \u001b[0;36m_get_data_features\u001b[1;34m(data_id, data_home)\u001b[0m\n\u001b[0;32m    342\u001b[0m     \u001b[0merror_message\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Dataset with data_id {} not found.\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    343\u001b[0m     json_data = _get_json_content_from_openml_api(url, error_message, True,\n\u001b[1;32m--> 344\u001b[1;33m                                                   data_home)\n\u001b[0m\u001b[0;32m    345\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data_features'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'feature'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kakkineni\\AppData\\Local\\Continuum\\anaconda3\\envs\\ipykernel_py2\\lib\\site-packages\\sklearn\\datasets\\openml.pyc\u001b[0m in \u001b[0;36m_get_json_content_from_openml_api\u001b[1;34m(url, error_message, raise_if_error, data_home)\u001b[0m\n\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_load_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[1;31m# 412 is an OpenML specific error code, indicating a generic error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kakkineni\\AppData\\Local\\Continuum\\anaconda3\\envs\\ipykernel_py2\\lib\\site-packages\\sklearn\\datasets\\openml.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m()\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mdata_home\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kakkineni\\AppData\\Local\\Continuum\\anaconda3\\envs\\ipykernel_py2\\lib\\site-packages\\sklearn\\datasets\\openml.pyc\u001b[0m in \u001b[0;36m_load_json\u001b[1;34m()\u001b[0m\n\u001b[0;32m    159\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_load_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    160\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mclosing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_openml_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_home\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kakkineni\\AppData\\Local\\Continuum\\anaconda3\\envs\\ipykernel_py2\\lib\\json\\__init__.pyc\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    337\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 339\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    340\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kakkineni\\AppData\\Local\\Continuum\\anaconda3\\envs\\ipykernel_py2\\lib\\json\\decoder.pyc\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    362\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m         \"\"\"\n\u001b[1;32m--> 364\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    365\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kakkineni\\AppData\\Local\\Continuum\\anaconda3\\envs\\ipykernel_py2\\lib\\json\\decoder.pyc\u001b[0m in \u001b[0;36mraw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    378\u001b[0m         \"\"\"\n\u001b[0;32m    379\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m             \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No JSON object could be decoded\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Expecting object: line 3 column 121540 (char 121541)"
     ]
    }
   ],
   "source": [
    "# Load the digit data from https://www.openml.org/d/554 or from default local location `~/scikit_learn_data/...`\n",
    "X, Y = fetch_openml(name='mnist_784', return_X_y=True, cache=False)\n",
    "\n",
    "# Rescale grayscale values to [0,1].\n",
    "X = X / 255.0\n",
    "\n",
    "# Shuffle the input: create a random permutation of the integers between 0 and the number of data points and apply this\n",
    "# permutation to X and Y.\n",
    "# NOTE: Each time you run this cell, you'll re-shuffle the data, resulting in a different ordering.\n",
    "shuffle = np.random.permutation(np.arange(X.shape[0]))\n",
    "X, Y = X[shuffle], Y[shuffle]\n",
    "\n",
    "print 'data shape: ', X.shape\n",
    "print 'label shape:', Y.shape\n",
    "\n",
    "# Set some variables to hold test, dev, and training data.\n",
    "test_data, test_labels = X[61000:], Y[61000:]\n",
    "dev_data, dev_labels = X[60000:61000], Y[60000:61000]\n",
    "train_data, train_labels = X[:60000], Y[:60000] \n",
    "mini_train_data, mini_train_labels = X[:1000], Y[:1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(1) Create a 10x10 grid to visualize 10 examples of each digit. Python hints:\n",
    "\n",
    "- plt.rc() for setting the colormap, for example to black and white\n",
    "- plt.subplot() for creating subplots\n",
    "- plt.imshow() for rendering a matrix\n",
    "- np.array.reshape() for reshaping a 1D feature vector into a 2D matrix (for rendering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P1(num_examples=10):\n",
    "    #Defining the colormap for image properties\n",
    "    plt.rc('image', cmap='gray')\n",
    "    plt.figure(figsize=(num_examples,num_examples))\n",
    "\n",
    "    # for each digit in 0-9 -> the unique labels in Y covers this part\n",
    "    for i in np.unique(Y):\n",
    "        features = X[Y == i][:num_examples]\n",
    "        for j in range(num_examples):\n",
    "               # Create subplot by specifying position from 1 to each digit * columns. Add j to get all columns\n",
    "                plt.subplot(num_examples, num_examples, 1 + int (i) * num_examples + j  )\n",
    "                # Hide axes\n",
    "                plt.axis('off')\n",
    "                # Plot the corresponding digit ( reshaped to 2D matrix)\n",
    "                vector_size = int(np.sqrt(features.shape[1]))\n",
    "                digit = features[j].reshape((vector_size,vector_size))            \n",
    "                plt.imshow(digit)\n",
    "\n",
    "P1(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) Evaluate a K-Nearest-Neighbors model with k = [1,3,5,7,9] using the mini training set. Report accuracy on the dev set. For k=1, show precision, recall, and F1 for each label. Which is the most difficult digit?\n",
    "\n",
    "- KNeighborsClassifier() for fitting and predicting\n",
    "- classification_report() for producing precision, recall, F1 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P2(k_values):\n",
    "    for i in k_values:\n",
    "        # create KNN neigh model from sklearn\n",
    "        neigh = KNeighborsClassifier(n_neighbors=i)\n",
    "        # fit the KNN model using mini training data and mini training labels set\n",
    "        neigh.fit(mini_train_data,mini_train_labels)\n",
    "        # prediction on the dev data set\n",
    "        dev_prediction_labels = neigh.predict(dev_data)\n",
    "        # Report the accuracy on the dev data set\n",
    "        print 'Accuracy for k-> {0:d} neighbours: {1:.3f}'.format(i,neigh.score(dev_data,dev_labels)) \n",
    "        #For k=1, show precision, recall, and F1 for each label\n",
    "        if i==1:\n",
    "            target_names = np.unique(Y)\n",
    "            print '\\nPrecission, recall, and F1 for each digit when k = 1:'\n",
    "            print classification_report(dev_labels, dev_prediction_labels, target_names = target_names)\n",
    "            \n",
    "k_values = [1, 3, 5, 7, 9]\n",
    "P2(k_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: Which is the most difficult digit for K=1?\n",
    "\n",
    "    From the classification report, looking at the f1-score which considers both precision and recall, the difficult digit is 8. \n",
    "    The recall value is @ 0.77 which means there are lot of false negatives.     \n",
    "    The precision is very low for digit 9 which is 0.8 implying that there are lot of false positives.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3) Using k=1, report dev set accuracy for the training set sizes below. Also, measure the amount of time needed for prediction with each training size.\n",
    "\n",
    "- time.time() gives a wall clock value you can use for timing operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P3(train_sizes, accuracies):\n",
    "    # create KNN neigh model from sklearn with k value 1\n",
    "    neigh = KNeighborsClassifier(n_neighbors=1)\n",
    "    # holder for times taken\n",
    "    time_taken = []\n",
    "    for size in train_sizes:\n",
    "        #start the timer\n",
    "        start = time.time()\n",
    "        # Get training sample from original data set\n",
    "        train_data_size, train_labels_size = X[:size], Y[:size]\n",
    "        # fit the KNN model using training sizes set\n",
    "        neigh.fit(train_data_size,train_labels_size)\n",
    "        #append the accuracy to accuracies\n",
    "        accuracies.append(neigh.score(dev_data,dev_labels))\n",
    "        end = time.time()\n",
    "        #calculate time and append it to time_taken\n",
    "        time_taken.append(end-start)\n",
    "    #printing the report with times taken for each training size\n",
    "    for size, accuracy, time_value in zip(train_sizes, accuracies, time_taken):\n",
    "        print(\" For Sample Size %5d, \\t  The Accuracy is -> %0.03f , Processing time is %.3f seconds\\n \"\n",
    "              % (size, accuracy,time_value))\n",
    "    \n",
    "train_sizes = [100, 200, 400, 800, 1600, 3200, 6400, 12800, 25000]\n",
    "accuracies = []\n",
    "\n",
    "P3(train_sizes, accuracies)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) Fit a regression model that predicts accuracy from training size. What does it predict for n=60000? What's wrong with using regression here? Can you apply a transformation that makes the predictions more reasonable?\n",
    "\n",
    "- Remember that the sklearn fit() functions take an input matrix X and output vector Y. So each input example in X is a vector, even if it contains only a single value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P4():\n",
    "    lr = LinearRegression(fit_intercept=True)\n",
    "    size = np.asarray([60000])\n",
    "    X = np.asarray(train_sizes)[:, np.newaxis]\n",
    "    y = np.asarray(accuracies)[:, np.newaxis]\n",
    "    lr.fit(X, y)\n",
    "    print 'Accuracy for n = 60000 for esitmated function y=a+bX is {0:s}'.format(lr.predict(size.reshape(1, -1)).tolist()[0])\n",
    "    \n",
    "    # The predicted value for n=60000 is greater than 1 which is not possible. \n",
    "    \n",
    "    plt.figure(figsize=(14, 2))\n",
    "  \n",
    "    #plotting the linear function\n",
    "    \n",
    "    ax = plt.subplot(1, 3, 1)\n",
    "    # Turn off tick marks to keep things clean.\n",
    "    plt.setp(ax, xticks=())\n",
    "    \n",
    "    x = np.linspace(X.min(), 60000, 100)[:,np.newaxis]\n",
    "    plt.plot(x, lr.predict(x))\n",
    "    plt.scatter(X, y, color='red')\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.title('Linear plot')\n",
    "    \n",
    "    # Applying log-transformation for the training values.\n",
    "  \n",
    "    logX = np.log(X)\n",
    "    size = np.log(size)\n",
    "    lr.fit(logX, y)\n",
    "    print 'Accuracy for n = 60000 for esitmated function y=a+blogX is {0:s}\\n'.format(lr.predict(size.reshape(1, -1)).tolist()[0])\n",
    "    ax = plt.subplot(1, 3, 2)\n",
    "    # Turn off tick marks to keep things clean.\n",
    "    plt.setp(ax, xticks=())\n",
    "    \n",
    "    x = np.linspace(np.log(X.min()), np.log(60000), 100)[:,np.newaxis]\n",
    "    plt.plot(x, lr.predict(x))\n",
    "    plt.scatter(np.log(X), y, color='red')\n",
    "    plt.xlabel(\"log x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.title('Log of X')\n",
    "    \n",
    "\n",
    "P4()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: \n",
    "\n",
    "    The predicted value for n=60000 is 1.24 and that is greater than 1 which is not possible. \n",
    "    \n",
    "    Even applying log transformation to our training values, the predicted value for n=60000 is 1.033 and that is still\n",
    "    greater than 1.\n",
    "    \n",
    "    We are using the size of the data set to predict the accuracy instead of values in the data set. That is something not\n",
    "    right when applying regression here.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a 1-NN and output a confusion matrix for the dev data. Use the confusion matrix to identify the most confused pair of digits, and display a few example mistakes.\n",
    "\n",
    "- confusion_matrix() produces a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P5():\n",
    "    # create KNN neigh model from sklearn with k value 1\n",
    "    neigh = KNeighborsClassifier(n_neighbors=1)\n",
    "   \n",
    "    # fit the KNN model using mini training set \n",
    "    neigh.fit(mini_train_data,mini_train_labels)\n",
    "    #prediction for dev data\n",
    "    pred_dev_labels = neigh.predict(dev_data)\n",
    "    #creating confusion matrix for the dev data\n",
    "    confusion_mat = confusion_matrix(dev_labels,pred_dev_labels)\n",
    "    #outputting confusion matrix\n",
    "    print \"confusion matrix when training the model with mini training data\\n\"\n",
    "    print confusion_mat\n",
    "\n",
    "    #Defining the colormap for image properties\n",
    "    plt.rc('image', cmap='gray')\n",
    "    plt.figure(figsize=(5,2))\n",
    "\n",
    "    # for each digit in 0-9 -> the unique labels in Y covers this part\n",
    "    \n",
    "    count = 1\n",
    "    for j in range(len(pred_dev_labels)):\n",
    "        if pred_dev_labels[j] == '9' and dev_labels[j] == '4' and count<=10: \n",
    "            features = np.array(dev_data[j]).reshape(28,28)\n",
    "            # Create subplot by specifying position from 1 to each digit * columns. Add j to get all columns\n",
    "            plt.subplot(2, 5, count)\n",
    "            # Hide axes\n",
    "            plt.axis('off')\n",
    "            plt.imshow(features)\n",
    "            count +=1\n",
    "                            \n",
    "                            \n",
    "P5()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examples: \n",
    "\n",
    "    Using Mini Training data:\n",
    "        When using the mini training data, the success rate seems to be little low compared to the training data.\n",
    "        For Digit 2, 6 times it is confused with digit 8 and 4 times each with 1 and 7.\n",
    "        For Digit 4, 11 times it is confused with digit 9.\n",
    "        For Digit 8, 22 times it is confused with other digits specially with 1,2 and 9.\n",
    "        For Digit 9, 7 times it is confused with digit 7.\n",
    "        \n",
    "        Digits 2, 4, 8 and 9 seems to be confused more compared to other digits.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(6) A common image processing technique is to smooth an image by blurring. The idea is that the value of a particular pixel is estimated as the weighted combination of the original value and the values around it. Typically, the blurring is Gaussian -- that is, the weight of a pixel's influence is determined by a Gaussian function over the distance to the relevant pixel.\n",
    "\n",
    "Implement a simplified Gaussian blur by just using the 8 neighboring pixels: the smoothed value of a pixel is a weighted combination of the original value and the 8 neighboring values. Try applying your blur filter in 3 ways:\n",
    "- preprocess the training data but not the dev data\n",
    "- preprocess the dev data but not the training data\n",
    "- preprocess both training and dev data\n",
    "\n",
    "Note that there are Guassian blur filters available, for example in scipy.ndimage.filters. You're welcome to experiment with those, but you are likely to get the best results with the simplified version I described above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gaussian_blur(image,sigma):\n",
    "    #get the nearest 9 neighbors to a pixel from the image\n",
    "    #create a KNN with 9 neighbors\n",
    "    neigh = KNeighborsClassifier(n_neighbors=9)\n",
    "    vector_size = int(np.sqrt(image.shape[0]))\n",
    "    #Take a copy of the image\n",
    "    blurred_image = np.copy(image)\n",
    "    #create a matrix with the vector_size\n",
    "    \n",
    "    \n",
    "def P6():\n",
    "    from scipy.ndimage.filters import gaussian_filter\n",
    "    \n",
    "    # create KNN neigh model from sklearn using 8 neighbors\n",
    "    neigh = KNeighborsClassifier(n_neighbors=8)\n",
    "    \n",
    "    #preprocessing the training data but not dev data\n",
    "    blur_mini_train_data = gaussian_filter(mini_train_data, sigma=0.5)\n",
    "\n",
    "    # fit the KNN model using blurred mini training data and mini training labels set\n",
    "    neigh.fit(blur_mini_train_data,mini_train_labels)\n",
    "    # Report the accuracy on the dev data set\n",
    "    print 'Accuracy for k-> 8 neighbours: {0:.3f}'.format(neigh.score(dev_data,dev_labels)) \n",
    "        \n",
    "    #preprocessing the dev data but not training data\n",
    "    blur_dev_data = gaussian_filter(dev_data, sigma=0.5)\n",
    "    # fit the KNN model using mini training data and mini training labels set\n",
    "    neigh.fit(mini_train_data,mini_train_labels)\n",
    "    # Report the accuracy on the dev data set\n",
    "    print 'Accuracy for k-> 8 neighbours: {0:.3f}'.format(neigh.score(blur_dev_data,dev_labels)) \n",
    "    \n",
    "    #preprocessing the both training data and dev data\n",
    "    # Report the accuracy on the dev data set\n",
    "     # fit the KNN model using blurred mini training data and mini training labels set\n",
    "    neigh.fit(blur_mini_train_data,mini_train_labels)\n",
    "    print 'Accuracy for k-> 8 neighbours: {0:.3f}'.format(neigh.score(blur_dev_data,dev_labels)) \n",
    "    \n",
    "Gaussian_blur(X[0],0.5)\n",
    "    \n",
    "P6()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: \n",
    "\n",
    "    Accuracy seems to be improved when we pre-process the training data but not the dev data\n",
    "    However accuracy is reduced when we only pre-process the dev data but not the training data\n",
    "    When both data sets are pre-processed, accuracy seems to be improved as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(7) Fit a Naive Bayes classifier and report accuracy on the dev data. Remember that Naive Bayes estimates P(feature|label). While sklearn can handle real-valued features, let's start by mapping the pixel values to either 0 or 1. You can do this as a preprocessing step, or with the binarize argument. With binary-valued features, you can use BernoulliNB. Next try mapping the pixel values to 0, 1, or 2, representing white, grey, or black. This mapping requires MultinomialNB. Does the multi-class version improve the results? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P7():\n",
    "    #For Binary Valued features using BernoulliNB\n",
    "    Binary_Bernoulli_model = BernoulliNB(binarize=0.333)\n",
    "    #Using Mini Training data to fit the model\n",
    "    Binary_Bernoulli_model.fit(mini_train_data, mini_train_labels)\n",
    "    print 'Accuracy using Bernoulli NB for dev set-> {0:.3f}'.format(Binary_Bernoulli_model.score(dev_data, dev_labels))\n",
    "\n",
    "    #For multinominal values, I am dividing the values  into 3 parts \n",
    "    #0 for values less than 0.333\n",
    "    #1 for values between 0.333 and 0.667\n",
    "    #2 for values greater than 0.667\n",
    "    Multinomial_model = MultinomialNB()\n",
    "    changed_mini_train_data_for_multinomial = np.where(mini_train_data < 0.333,0,\n",
    "                                      np.where((mini_train_data > 0.333) & (mini_train_data < 0.667), 1, 2))\n",
    "    changed_dev_data_for_multinomial = np.where(dev_data < 0.333,0,\n",
    "                                      np.where((dev_data > 0.333) & (dev_data < 0.667), 1, 2))\n",
    "    \n",
    "    #Using Transformed Mini Training data to fit the model\n",
    "    Multinomial_model.fit(changed_mini_train_data_for_multinomial, mini_train_labels)\n",
    "    \n",
    "    print 'Accuracy using Multinomial NB for dev set-> {0:.3f}'.format(\n",
    "        Multinomial_model.score(changed_dev_data_for_multinomial, dev_labels))\n",
    "\n",
    "P7()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: Does the multi-class version improve the results? Why or why not?\n",
    "\n",
    "    The multi-class version doesn't improve the results but they are not farther apart. It may fall more if we map the pixel values to more than 3 classes. Accuracy usually improves when the categories are less.\n",
    "    \n",
    "    I did try with binarize value 0.25 for Binomial NB, which gave accuracy 0.826 and 0.25,0.75,1 threshold limits for Multinomial NB which gave accuracy to 0.809. \n",
    "    \n",
    "    This looks less when compared to binarize threshold values 0.333 and 0.667 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(8) Use GridSearchCV to perform a search over values of alpha (the Laplace smoothing parameter) in a Bernoulli NB model. What is the best value for alpha? What is the accuracy when alpha=0? Is this what you'd expect?\n",
    "\n",
    "- Note that GridSearchCV partitions the training data so the results will be a bit different than if you used the dev data for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P8(alphas):\n",
    "    #creating a GridSearchCV using BernoulliNB estimator and passing the \n",
    "    nb = GridSearchCV(BernoulliNB(binarize=0.333), alphas)\n",
    "    nb.fit(mini_train_data, mini_train_labels)\n",
    "    means = nb.cv_results_['mean_test_score']\n",
    "    stds = nb.cv_results_['std_test_score']\n",
    "    for params, accuracy in zip(nb.cv_results_['params'], means ):\n",
    "        print(\" For %r \\t Accuracy -> %0.03f \"\n",
    "              % (params, accuracy))\n",
    "    return nb\n",
    "\n",
    "alphas = {'alpha': [0.0, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]}\n",
    "nb = P8(alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print nb.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: What is the best value for alpha? What is the accuracy when alpha=0? Is this what you'd expect?\n",
    "\n",
    "    The best value for alpha is 0.001\n",
    "    The accuracy at alpha=0 is 0.814 little less compared to the best value. When alpha=0, we are suggesting the Model, that \n",
    "    no smoothing is required, and so, it makes sense that the accuracy fall to an extent. And we are only looking \n",
    "    at P(label) instead of P(label|feature). Yes, I would expect it to be that way."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(9) Try training a model using GuassianNB, which is intended for real-valued features, and evaluate on the dev data. You'll notice that it doesn't work so well. Try to diagnose the problem. You should be able to find a simple fix that returns the accuracy to around the same rate as BernoulliNB. Explain your solution.\n",
    "\n",
    "Hint: examine the parameters estimated by the fit() method, theta\\_ and sigma\\_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P9():\n",
    "    gnb = GaussianNB()\n",
    "    print gnb\n",
    "    gnb.fit(mini_train_data, mini_train_labels)\n",
    "    print 'Accuracy using Gaussian NB for dev set-> {0:.3f}'.format(gnb.score(dev_data, dev_labels))\n",
    "    \n",
    "    #The theta_ gives mean of each feature per class\n",
    "    print gnb.theta_.mean(axis=1)\n",
    "    #The sigma_ gives mean of each feature per class\n",
    "    print gnb.sigma_.mean(axis=1)\n",
    "\n",
    "    #For a Gaussian NB to work accurately, we need the data to be normally distributed. \n",
    "    # check the normality for an example image\n",
    "    image_example = X[0]\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1,1,1)\n",
    "    fig = plt.hist(image_example)\n",
    "    plt.title('Histogram of a random image')\n",
    "    \n",
    "    #we can see that the data is not normally distributed as most values are either 0 or 1, lets change some variance \n",
    "    #and see if the Gaussian Classifier improves the accuracy.\n",
    "    \n",
    "    new_sigma_values = np.arange(0,1,0.05)\n",
    "    \n",
    "    for i in new_sigma_values:\n",
    "        for digit in range(10):\n",
    "            for feature in range(X.shape[1]):\n",
    "                gnb.sigma_[digit][feature] = i\n",
    "            \n",
    "        print 'Accuracy using Gaussian NB for dev set using with sigma {0:.3f} -> {1:.3f} '.format(i,gnb.score(dev_data, dev_labels))\n",
    "     \n",
    "    \n",
    "    # Observing the accuracies by altering sigma values, we found 0.05,0.1,0.15,0.2,0.25,0.3 \n",
    "    \n",
    "    updated_sigma_values = [0.05,0.1,0.15,0.2,0.25,0.3]\n",
    "    #lets trying adding normal random noise to the mini training data using the updated sigma values\n",
    "    for i in range(len(updated_sigma_values)):\n",
    "        noised_mini_train_data = mini_train_data + np.random.normal(0.0, updated_sigma_values[i], mini_train_data.shape)\n",
    "        gnb.fit(noised_mini_train_data, mini_train_labels)\n",
    "        print 'Accuracy using for dev set when adding random noise with sigma {0:.3f} -> {1:.3f} '.format(updated_sigma_values[i],gnb.score(dev_data, dev_labels))\n",
    "            \n",
    "\n",
    "gnb = P9()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: \n",
    "\n",
    "    Two ways, I could improve the Gaussian NB\n",
    "    - One by adding variance to the data\n",
    "    - Two by adding some random normal noise to the training data\n",
    "    \n",
    "    As Gaussian distribution works best if the data is normalized, our image data consists mostly values either 0 or 1. So, to improve the classifier, I tried the above two ways, which got the accuracy 0.803 when added variance with the sigma value 0.05 and 0.818 when adding random normal noise with the sigma value 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(10) Because Naive Bayes is a generative model, we can use the trained model to generate digits. Train a BernoulliNB model and then generate a 10x20 grid with 20 examples of each digit. Because you're using a Bernoulli model, each pixel output will be either 0 or 1. How do the generated digits compare to the training digits?\n",
    "\n",
    "- You can use np.random.rand() to generate random numbers from a uniform distribution\n",
    "- The estimated probability of each pixel is stored in feature\\_log\\_prob\\_. You'll need to use np.exp() to convert a log probability back to a probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P10(num_examples):\n",
    "\n",
    "    #For Binary Valued features using BernoulliNB\n",
    "    Binary_Bernoulli_model = BernoulliNB(binarize=0.333)\n",
    "    #Using Mini Training data to fit the model\n",
    "    Binary_Bernoulli_model.fit(mini_train_data, mini_train_labels)\n",
    "    #Get the probability values from the model\n",
    "    probs = np.exp(Binary_Bernoulli_model.feature_log_prob_)\n",
    "    #Defining the colormap for image properties\n",
    "    plt.rc('image', cmap='gray')\n",
    "    plt.figure(figsize=(10,10))\n",
    "\n",
    "    # for each digit in 0-9 -> the unique labels in Y covers this part\n",
    "    for i in range(len(np.unique(Y))):\n",
    "        # using np.random.rand(784L) here as Bernoulli NB model needs 0 and 1 values\n",
    "        # we turn on if the value of the random is less than the probability the model has given us\n",
    "        features = np.where(probs[i,]>np.random.rand(X.shape[1]),1,0)\n",
    "        for j in range(num_examples):\n",
    "               # Create subplot by specifying position from 1 to each digit * columns. Add j to get all columns\n",
    "                plt.subplot(len(np.unique(Y)), num_examples, 1 + int (i) * num_examples + j  )\n",
    "                # Hide axes\n",
    "                plt.axis('off')\n",
    "                # Plot the corresponding digit ( reshaped to 2D matrix)\n",
    "                vector_size = int(np.sqrt(X.shape[1]))\n",
    "                digit = features.reshape((vector_size,vector_size))            \n",
    "                plt.imshow(digit)\n",
    "\n",
    "P10(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: How do the generated digits compare to the training digits?\n",
    "    \n",
    "    The generated digits are much lighter in color and unable to read clearly when compared to the training digits. \n",
    "    But given the probabilities, they show that those digits stay in the right place for the given training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(11) Remember that a strongly calibrated classifier is rougly 90% accurate when the posterior probability of the predicted class is 0.9. A weakly calibrated classifier is more accurate when the posterior is 90% than when it is 80%. A poorly calibrated classifier has no positive correlation between posterior and accuracy.\n",
    "\n",
    "Train a BernoulliNB model with a reasonable alpha value. For each posterior bucket (think of a bin in a histogram), you want to estimate the classifier's accuracy. So for each prediction, find the bucket the maximum posterior belongs to and update the \"correct\" and \"total\" counters.\n",
    "\n",
    "How would you characterize the calibration for the Naive Bayes model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def P11(buckets, correct, total):\n",
    "    \n",
    "    #Using BinomialNB with the best alpha and a binarize value of 0.333\n",
    "    Binary_Bernoulli_model = BernoulliNB(alpha=0.001, binarize=0.333)\n",
    "    #Using Mini Training data to fit the model\n",
    "    Binary_Bernoulli_model.fit(mini_train_data, mini_train_labels)\n",
    "    #Get the predicted labels for the dev data set\n",
    "    dev_predicted_labels = Binary_Bernoulli_model.predict(dev_data)\n",
    "    #Get the predicted probabilites for the dev data set.\n",
    "    #This returns the probability estimate for the dev data set\n",
    "    dev_predicted_probs = Binary_Bernoulli_model.predict_proba(dev_data)\n",
    " \n",
    "\n",
    "    #for each bucket - need to look at previous value to get the correct bin\n",
    "    for i in range(len(buckets)):\n",
    "        #for all the probabilites for the entire set\n",
    "        #set counter for total_value and correct_value\n",
    "        total_value = 0\n",
    "        correct_value = 0\n",
    "        for j in range(dev_predicted_probs.shape[0]):\n",
    "            # increment correct value only if total is incremented\n",
    "            increment_value = False\n",
    "            #Get the maximum probability, that the model predicts\n",
    "            prob_of_digit = dev_predicted_probs[j, dev_predicted_probs[j].argmax()]\n",
    "            \n",
    "            #place it in the bucket\n",
    "            #if the probability of the digit is in the current bucket\n",
    "            if i == 0:\n",
    "                increment_correct = np.where((prob_of_digit <= buckets[i]),True, False)\n",
    "            else:     \n",
    "                increment_correct = np.where((prob_of_digit <= buckets[i]) & (prob_of_digit > buckets[i-1]), True, False)\n",
    "            \n",
    "            #if the prediction of the label is correct for the given bucket\n",
    "            if increment_correct: \n",
    "                total_value +=1\n",
    "                if(dev_predicted_labels[j] == dev_labels[j]):\n",
    "                    correct_value +=1\n",
    "                \n",
    "        \n",
    "        #place the total_value and correct_value in the respective buckets\n",
    "        correct[i] = float(correct_value)\n",
    "        total[i] = float(total_value)\n",
    "\n",
    "\n",
    "buckets = [0.5, 0.9, 0.999, 0.99999, 0.9999999, 0.999999999, 0.99999999999, 0.9999999999999, 1.0]\n",
    "correct = [0 for i in buckets]\n",
    "total = [0 for i in buckets]\n",
    "\n",
    "P11(buckets, correct, total)\n",
    "\n",
    "for i in range(len(buckets)):\n",
    "    accuracy = 0.0\n",
    "    if (total[i] > 0): accuracy = correct[i] / total[i]\n",
    "    print 'p(pred) <= %.13f    total = %3d  correct = %3d  accuracy = %.3f' %(buckets[i], total[i],  correct[i], accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANSWER: How would you characterize the calibration for the Naive Bayes model?\n",
    "\n",
    "    The accuracy is low at probability bucket 0.5-0.9 which is 0.406 compared to the accuracy at 0.9999999999900 which is \n",
    "    0.814.\n",
    "    This shows that the naive bayes model's precision is different from accuracy.\n",
    "    As Accuracy is precision with calibration, when the posterior probability of the predicted class is 0.9 our model \n",
    "    shows only 0.406 accuracy. This shows that our model is not perfectly calibrated shows signs of weakly calibrated \n",
    "    classifier. So, we cannot simply infer the correct digit even though the posterior probability is at 0.9     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(12) EXTRA CREDIT\n",
    "\n",
    "Try designing extra features to see if you can improve the performance of Naive Bayes on the dev set. Here are a few ideas to get you started:\n",
    "- Try summing the pixel values in each row and each column.\n",
    "- Try counting the number of enclosed regions; 8 usually has 2 enclosed regions, 9 usually has 1, and 7 usually has 0.\n",
    "\n",
    "Make sure you comment your code well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def P12():\n",
    "\n",
    "### STUDENT START ###\n",
    "\n",
    "\n",
    "### STUDENT END ###\n",
    "\n",
    "#P12()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
